{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update: 19 April 2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a28bd",
   "metadata": {},
   "source": [
    "# Post Processing Stage 1: Get the HIGHEST rank Structure for each Protein predicted by AlphaFold3\n",
    "- Goal: Convert every predictions to DSSP format and store the results in a specified directory.\n",
    "- Input: AlphaFold3 predictions in mmCIF format \n",
    "- Output: DSSP format files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the path to the predictions directory\n",
    "prediction_path = '../Data/Predictions'\n",
    "output_path = '../Data/Postprocessed'\n",
    "\n",
    "cb513_path = os.path.join(output_path, 'CB513')\n",
    "ts115_path = os.path.join(output_path, 'TS115')\n",
    "casp10_path = os.path.join(output_path, 'CASP10')\n",
    "\n",
    "# Create a new directory for the highest confident predictions\n",
    "os.makedirs(os.path.join(output_path), exist_ok=True)\n",
    "os.makedirs(os.path.join(cb513_path), exist_ok=True)\n",
    "os.makedirs(os.path.join(ts115_path), exist_ok=True)\n",
    "os.makedirs(os.path.join(casp10_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_confident_predictions(dataset_name):\n",
    "    \"\"\"\n",
    "    This function processes the prediction files in the specified dataset and copies the highest confident predictions to a new directory.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): The name of the dataset (e.g., 'CB513', 'TS115', 'CASP10').\n",
    "    \"\"\"\n",
    "    # Map dataset_name to its corresponding path and max index\n",
    "    dataset_info = {\n",
    "        'CB513': (cb513_path, 513),\n",
    "        'TS115': (ts115_path, 115),\n",
    "        'CASP10': (casp10_path, 122)\n",
    "    }\n",
    "    \n",
    "    dataset_path, max_index = dataset_info.get(dataset_name, (None, None))\n",
    "\n",
    "    if not dataset_path:\n",
    "        print(f\"Invalid dataset name: {dataset_name}\")\n",
    "        return\n",
    "\n",
    "    # Initialize a set of all expected indices\n",
    "    expected_indices = set(range(max_index + 1))\n",
    "    found_indices = set()\n",
    "\n",
    "    # Iterate through each folder in the dataset path\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        # Check if the folder name starts with the dataset name and is a directory\n",
    "        if folder.startswith(dataset_name) and os.path.isdir(os.path.join(dataset_path, folder)):\n",
    "            folder_path = os.path.join(dataset_path, folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                # Check if the file is a .cif file\n",
    "                if file.endswith('.cif'):\n",
    "                    # Check if the file is the highest confident one\n",
    "                    # Name format: fold_{dataset_name}_{index}_model_0 -> 0 is the highest confident\n",
    "                    if file.startswith(f'fold_{dataset_name.lower()}') and file.endswith('_model_0.cif'):\n",
    "                        # Extract the index from the file name\n",
    "                        try:\n",
    "                            index = int(file.split('_')[2])\n",
    "                            found_indices.add(index)\n",
    "                        except (IndexError, ValueError):\n",
    "                            print(f\"Failed to extract index from file name: {file}\")\n",
    "                        \n",
    "                        # Copy the file to the new directory\n",
    "                        src = os.path.join(folder_path, file)\n",
    "                        dst = os.path.join(output_path, dataset_name, file)\n",
    "                        shutil.copy(src, dst)\n",
    "                        # Check if the file was copied successfully\n",
    "                        if os.path.exists(dst):\n",
    "                            print(f'File successfully copied to {dst}')\n",
    "                        else:\n",
    "                            print(f'Failed to copy file to {dst}')\n",
    "\n",
    "    # Calculate missing indices\n",
    "    missing_indices = expected_indices - found_indices\n",
    "    if missing_indices:\n",
    "        print(f\"Missing indices for {dataset_name}: {sorted(missing_indices)}\")\n",
    "    else:\n",
    "        print(f\"All indices are present for {dataset_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83795973",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_highest_confident_predictions('CB513')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843350d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_highest_confident_predictions('TS115')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_highest_confident_predictions('CASP10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edca1e",
   "metadata": {},
   "source": [
    "# Post Processing Stage 2: Convert tertiary structure predictions to secondary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f63a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from Bio.PDB import MMCIFParser, DSSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cbefb",
   "metadata": {},
   "source": [
    "## DSSP Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bba0ff",
   "metadata": {},
   "source": [
    "> WINDOWS BELUM KOMPATIBEL! GUNAKAN OS LINUX!\n",
    "\n",
    "> PASTIKAN PACKAGE DSSP & BIOPYTHON SUDAH TERINSTAL\n",
    "\n",
    "[DSSP](https://github.com/PDB-REDO/dssp):\n",
    "```bash\n",
    "    git clone https://github.com/PDB-REDO/dssp.git\n",
    "    cd dssp\n",
    "    cmake -S . -B build\n",
    "    cmake --build build\n",
    "    cmake --install build\n",
    "```\n",
    "    \n",
    "BIOPYTHON:\n",
    "```python\n",
    "    !pip install biopython\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5d44d",
   "metadata": {},
   "source": [
    "## Landasan Teori DSSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b9f8d5",
   "metadata": {},
   "source": [
    "Biopython DSSP Secondary structure classification\n",
    "\n",
    "| Code | Structure                     |\n",
    "|------|-------------------------------|\n",
    "| H    | Alpha helix (4-12)            |\n",
    "| B    | Isolated beta-bridge residue  |\n",
    "| E    | Strand                        |\n",
    "| G    | 3-10 helix                    |\n",
    "| I    | Pi helix                      |\n",
    "| T    | Turn                          |\n",
    "| S    | Bend                          |\n",
    "| -    | None                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b74352",
   "metadata": {},
   "source": [
    "PDB-REDO DSSP Secondary structure classification\n",
    "| DSSP Code | mmCIF Code      | Description   |\n",
    "|-----------|-----------------|---------------|\n",
    "| H         | HELX_RH_AL_P    | Alphahelix    |\n",
    "| B         | STRN            | Betabridge    |\n",
    "| E         | STRN            | Strand        |\n",
    "| G         | HELX_RH_3T_P    | Helix_3       |\n",
    "| I         | HELX_RH_PI_P    | Helix_5       |\n",
    "| P         | HELX_LH_PP_P    | Helix_PPII    |\n",
    "| T         | TURN_TY1_P      | Turn          |\n",
    "| S         | BEND            | Bend          |\n",
    "| ' ' (space)| OTHER          | Loop          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7efac",
   "metadata": {},
   "source": [
    "Bipython DSSP Tuple Output per Residue\n",
    "| Tuple Index | Value                     |\n",
    "|-------------|---------------------------|\n",
    "| 0           | DSSP index               |\n",
    "| 1           | Amino acid               |\n",
    "| 2           | Secondary structure      |\n",
    "| 3           | Relative ASA             |\n",
    "| 4           | Phi                      |\n",
    "| 5           | Psi                      |\n",
    "| 6           | NH–>O_1_relidx           |\n",
    "| 7           | NH–>O_1_energy           |\n",
    "| 8           | O–>NH_1_relidx           |\n",
    "| 9           | O–>NH_1_energy           |\n",
    "| 10          | NH–>O_2_relidx           |\n",
    "| 11          | NH–>O_2_energy           |\n",
    "| 12          | O–>NH_2_relidx           |\n",
    "| 13          | O–>NH_2_energy           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = MMCIFParser(QUIET=True)\n",
    "file_path = \"../Data/Postprocessed/CASP10/fold_casp10_0_model_0.cif\"\n",
    "struktur = parser.get_structure('struktur', file_path)\n",
    "dssp = DSSP(model=struktur[0], in_file=file_path, dssp='mkdssp')\n",
    "# Print 14 fitur dari setiap asam amino \n",
    "for data_dssp in dssp:\n",
    "    print(data_dssp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295958a",
   "metadata": {},
   "source": [
    "## Hitung DSSP dengan bipython (lama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b04b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_dssp(dataset_name):\n",
    "#     \"\"\"\n",
    "#     Calculates DSSP features for each protein (mmCIF file) in the specified dataset and saves the results to a CSV file.\n",
    "\n",
    "#     Args:\n",
    "#         dataset_name (str): The name of the dataset (e.g., 'casp10', 'cb513', 'ts115').\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     # Initialize the parser for reading mmCIF files\n",
    "#     parser = MMCIFParser(QUIET=True)\n",
    "    \n",
    "#     # Define the directories for input and output\n",
    "#     input_directory = f\"../Data/Postprocessed/{dataset_name}/\"\n",
    "#     output_file = f\"../Data/Postprocessed/DSSP_{dataset_name}.csv\"\n",
    "    \n",
    "#     protein_data = []\n",
    "\n",
    "#     # Iterate through all files in the input directory\n",
    "#     for file_name in os.listdir(input_directory):\n",
    "#         # Process only mmCIF files\n",
    "#         if file_name.endswith('.cif'):\n",
    "#             file_path = os.path.join(input_directory, file_name)\n",
    "#             print(f\"Processing file: {file_path}...\")\n",
    "#             try:\n",
    "#                 # Parse the structure from the mmCIF file\n",
    "#                 structure = parser.get_structure('structure', file_path)\n",
    "#                 # Compute secondary structure using DSSP\n",
    "#                 dssp = DSSP(model=structure[0], in_file=file_path, dssp='mkdssp')\n",
    "#                 # Append the DSSP results to the list\n",
    "#                 protein_data.append([file_name, dssp])\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "#     feature_data = []\n",
    "\n",
    "#     # Process DSSP results for each protein\n",
    "#     for protein in protein_data:\n",
    "#         file_name, dssp = protein\n",
    "#         residues = ''\n",
    "#         secondary_structure = ''\n",
    "#         # Concatenate all residues and secondary structure elements into strings\n",
    "#         for dssp_entry in dssp:\n",
    "#             residues += dssp_entry[1]\n",
    "#             secondary_structure += dssp_entry[2]\n",
    "#         feature_data.append([file_name, len(residues), residues, secondary_structure])\n",
    "\n",
    "#     # Convert the data into a pandas DataFrame\n",
    "#     df = pd.DataFrame(feature_data, columns=['file_name', 'length', 'residues', 'secondary_structure'])\n",
    "#     # Extract the ID from the file name\n",
    "#     df['id'] = df['file_name'].apply(lambda x: int(x.split('_')[2]))\n",
    "#     # Drop the file_name column\n",
    "#     df.drop(columns=['file_name'], inplace=True)\n",
    "#     # Reorder columns to place 'id' at the front\n",
    "#     df = df[['id', 'length', 'residues', 'secondary_structure']]\n",
    "#     # Sort the DataFrame by 'id'\n",
    "#     df.sort_values(by=['id'], inplace=True)\n",
    "#     # Save the DataFrame to a CSV file\n",
    "#     df.to_csv(output_file, index=False)\n",
    "\n",
    "#     print(f\"DSSP data successfully saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18096eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DSSP dataset casp10\n",
    "# data_protein_casp10 = calculate_dssp('CASP10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b79f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DSSP dataset casp10\n",
    "# data_protein_casp10 = calculate_dssp('CB513')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbe181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DSSP dataset casp10\n",
    "# data_protein_casp10 = calculate_dssp('TS115')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac240b",
   "metadata": {},
   "source": [
    "## Hitung DSSP via Script bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330cec4",
   "metadata": {},
   "source": [
    "Script ada di `convert.sh` dan `convert_dsspcif.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771929ca",
   "metadata": {},
   "source": [
    "## Function to extract secondary structure from `.dssp` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssp_file_path = '..Data/Postprocessed/CB513/fold_cb513_0_model_0.dssp'\n",
    "\n",
    "real_residue_cb513_0 = 'VPSLATISLENSWSGLSKQIQLAQGNNGIFRTPIVLVDNKGNRVQITNVTSKVVTSNIQLLLNTRNI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92babd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xx: VPSLATISLENSWSGLSKQIQLAQGNNGIFRTPIVLVDNKGNRVQITNVTSKVVTSNIQLLLNTRNI\n",
      "aa: VPSLATISLENSWSGLSKQIQLAQGNNGIFRTPIVLVDNKGNRVQITNVTSKVVTSNIQLLLNTRNI\n",
      "ss: ---HHHHHHHHHHHHHHHHHHHHTTTTTEEEEEEEEE-TTS-EEEEEETTSHHHHHHHHHHHHHHH-\n"
     ]
    }
   ],
   "source": [
    "def extract_secondary_structure(dssp_file):\n",
    "    \"\"\"\n",
    "    Extracts the residue and secondary structure sequence from a DSSP file.\n",
    "\n",
    "    Args:\n",
    "        dssp_file (str): Path to the DSSP file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the residue and secondary structure sequence.\n",
    "    \"\"\"\n",
    "    residues = \"\"\n",
    "    secondary_structure = \"\"\n",
    "    # Open the DSSP file and read its contents\n",
    "    with open(dssp_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        start_reading = False\n",
    "        for line in lines:\n",
    "            if line.startswith(\n",
    "                    \"  #  RESIDUE\"):  # Start reading after this line\n",
    "                start_reading = True\n",
    "                continue\n",
    "            if start_reading:\n",
    "                if line.strip() == \"\":\n",
    "                    continue\n",
    "                # Extract residue (AA column) and secondary structure (STRUCTURE column)\n",
    "                residue = line[13].strip()  # from left, column 14\n",
    "                structure = line[16]  # from left, column 17\n",
    "                # If the structure is a space, set it \"-\"\n",
    "                if structure == \" \":\n",
    "                    structure = \"-\"\n",
    "                # Append the residue and structure\n",
    "                residues += residue\n",
    "                secondary_structure += structure\n",
    "    return residues, secondary_structure\n",
    "\n",
    "# Example usage\n",
    "residue, secondary_structure = extract_secondary_structure(dssp_file_path)\n",
    "print(f\"xx: {real_residue_cb513_0}\")\n",
    "print(f\"aa: {residue}\")\n",
    "print(f\"ss: {secondary_structure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebeb57",
   "metadata": {},
   "source": [
    "## Extract SS from every dssp files inside a dataset folder\n",
    "- Extract the secondary structures of every protein in dataset\n",
    "- Secondary structure is stored in `.dssp` files previously generated by `convert.sh` bash script\n",
    "- Save them into a single CSV file\n",
    "\n",
    "  \\- columns are: id, length, residue, predicted_dssp8\n",
    "\n",
    "- The input dssp file name format: fold_{dataset_name}_{index}_model_0.dssp\n",
    "\n",
    "  \\- for example: fold_casp10_0_model_0.dssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..Data/Postprocessed/'\n",
    "cb513_dssp_path = os.path.join(path, 'CB513')\n",
    "ts115_dssp_path = os.path.join(path, 'TS115')\n",
    "casp10_dssp_path = os.path.join(path, 'CASP10')\n",
    "cb513_output_path = os.path.join(path, 'cb513_dssp.csv')\n",
    "ts115_output_path = os.path.join(path, 'ts115_dssp.csv')\n",
    "casp10_output_path = os.path.join(path, 'casp10_dssp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "440d8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dssp_data(dssp_path, output_path):\n",
    "    \"\"\"\n",
    "    This function extracts secondary structure data from DSSP files in a single directory,\n",
    "    sorts them by ID, and combines them into a single CSV file.\n",
    "    \n",
    "    Args:\n",
    "        dssp_path (str): The path to the directory containing DSSP files.\n",
    "        output_path (str): The path to the output CSV file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for file in os.listdir(dssp_path):\n",
    "        if file.endswith('.dssp'):\n",
    "            # Extract the index from the file name\n",
    "            try:\n",
    "                index = int(file.split('_')[2])\n",
    "            except (IndexError, ValueError):\n",
    "                print(f\"Failed to extract index from file name: {file}\")\n",
    "                continue\n",
    "            \n",
    "            # Read the DSSP file and extract secondary structure\n",
    "            dssp_file = os.path.join(dssp_path, file)\n",
    "            residues, secondary_structure = extract_secondary_structure(dssp_file)\n",
    "            length = len(residues)\n",
    "\n",
    "            # Append the data to the list\n",
    "            data.append((index, length, residues, secondary_structure))\n",
    "    \n",
    "    # Sort the data by ID\n",
    "    data.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Write the sorted data to the CSV file\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        outfile.write(\"id,length,residue,predicted_dssp8\\n\")  # Write header\n",
    "        for entry in data:\n",
    "            outfile.write(f\"{entry[0]},{entry[1]},{entry[2]},{entry[3]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92471aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dssp_data(cb513_dssp_path, cb513_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d673ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dssp_data(ts115_dssp_path, ts115_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36aa757",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dssp_data(casp10_dssp_path, casp10_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
